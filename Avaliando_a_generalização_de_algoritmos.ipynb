{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Avaliando a generalização de algoritmos.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN1PyR3Fs+xEnDJYWcMpykM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RenanCostaNascimento/mestrado-reconhecimento-padroes/blob/main/Avaliando_a_generaliza%C3%A7%C3%A3o_de_algoritmos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mqw1_y01BNZ"
      },
      "source": [
        "O objetivo deste Notebook é comparar classificadores. Os classificadores escolhidos são o [Logistic Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) e o [KNN](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) do scikit-learn. Vamos começar importando a base de dados [Heart Disease UCI do Kaggle](https://www.kaggle.com/ronitf/heart-disease-uci). É um dataset que indica se a pessoa tem alguma condição cardíaca com base nas suas informações médicas.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZA9LrvqOyoUG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "715bc456-89e4-41f1-f775-a34e4d70f5e7"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "dataset = pd.read_csv('/content/heart.csv')\n",
        "dataset.head(3)"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>63</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>145</td>\n",
              "      <td>233</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>150</td>\n",
              "      <td>0</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>37</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>130</td>\n",
              "      <td>250</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>187</td>\n",
              "      <td>0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>41</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>130</td>\n",
              "      <td>204</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>172</td>\n",
              "      <td>0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age  sex  cp  trestbps  chol  fbs  ...  exang  oldpeak  slope  ca  thal  target\n",
              "0   63    1   3       145   233    1  ...      0      2.3      0   0     1       1\n",
              "1   37    1   2       130   250    0  ...      0      3.5      0   0     2       1\n",
              "2   41    0   1       130   204    0  ...      0      1.4      2   0     2       1\n",
              "\n",
              "[3 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iARPNBt52qAF"
      },
      "source": [
        "Os dados da base de dados devem ser pré-processados. Para tanto, vamos começar separando os dados em uma matriz de features (dados de entrada) e um vetor coluna com as classes (última coluna – “target” – do arquivo csv)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiolejW022Xj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf518d06-8ef9-4f46-fdf8-aa9b6a15a1e3"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# transforma o dataset do pandas em np array\n",
        "featureMatrix = dataset.to_numpy()\n",
        "\n",
        "# extrai a ultima coluna da matrix\n",
        "labels = featureMatrix[:,len(featureMatrix[0]) - 1]\n",
        "\n",
        "# remove a ultima coluna da featureMatrix\n",
        "featureMatrix = np.delete(featureMatrix, len(featureMatrix[0]) - 1, 1)\n",
        "\n",
        "np.shape(featureMatrix), np.shape(labels)"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((303, 13), (303,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHCUyk_NDYmt"
      },
      "source": [
        "Agora precisamos dividir nossa base de dados em treino e teste. Para fazer isso vamos utilizar a função [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) do sklearn. Em seguida precisamos de fato treinar nossos modelos. Para garantir que a comparação dos classificadores seja feita da melhor forma possível, vamos treinar o modelo de 10 formas diferentes, cada uma com um random_state único. Isso nos dará 20 modelos distintos, um para cada classificador. Para facilitar o trabalho, abaixo definimos uma função que separa a base de dados em teste e treino, além de treinar os modelos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6vrffEhDiHu"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "def trainTestSplit(randomState):\n",
        "  return train_test_split(featureMatrix, labels, test_size=0.33, random_state=randomState)\n",
        "\n",
        "def trainModels(featuresTrain, labelsTrain):\n",
        "  # eu precisei colocar o max_iter=1000 porque estava dando esse erro sem ele:\n",
        "  #  ConvergenceWarning: lbfgs failed to converge (status=1): STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
        "  logisticModel = LogisticRegression(max_iter=10000)\n",
        "  logisticModel.fit(featuresTrain, labelsTrain)\n",
        "\n",
        "  knnModel = KNeighborsClassifier()\n",
        "  knnModel.fit(featuresTrain, labelsTrain)\n",
        "\n",
        "  return logisticModel, knnModel"
      ],
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "byCTvhss4gQh"
      },
      "source": [
        "Com a função de treinamento definida, vamos agora criar outra função para avaliar os resultados. A avaliação será feita utilizando as métricas [Mean Squared Error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html) e [F1 Score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html), ambas do sklearn."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UXB4REH4ur0"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def evaluateModel(model, featuresTest, labelsTest):\n",
        "  prediction = model.predict(featuresTest)\n",
        "  mse = mean_squared_error(labelsTest, prediction)\n",
        "  f1Score = f1_score(labelsTest, prediction)\n",
        "\n",
        "  return mse, f1Score"
      ],
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsVTSYIjPkSb"
      },
      "source": [
        "Por fim, vamos executar todo esse procedimento 10 vezes e tirar a média das métricas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6gXyksrQPkri",
        "outputId": "11948014-7b22-401b-cbbd-704d5619e2aa"
      },
      "source": [
        "logisticErrors = []\n",
        "logisticScores = []\n",
        "knnErrors = []\n",
        "knnScores = []\n",
        "\n",
        "for test in range(10):\n",
        "  featuresTrain, featuresTest, labelsTrain, labelsTest = trainTestSplit(test)\n",
        "  logisticModel, knnModel = trainModels(featuresTrain, labelsTrain)\n",
        "\n",
        "  logisticMse, logisticF1Score = evaluateModel(logisticModel, featuresTest, labelsTest)\n",
        "  logisticErrors.append(logisticMse)\n",
        "  logisticScores.append(logisticF1Score)\n",
        "\n",
        "  knnMse, knnF1Score = evaluateModel(knnModel, featuresTest, labelsTest)\n",
        "  knnErrors.append(knnMse)\n",
        "  knnScores.append(knnF1Score)\n",
        "\n",
        "print(f\"Logistic Mean MSE: {np.mean(logisticErrors)}\")\n",
        "print(f\"KNN Mean MSE: {np.mean(knnErrors)}\")\n",
        "print(\"---------\")\n",
        "print(f\"Logistic F1 Score: {np.mean(logisticScores)}\")\n",
        "print(f\"KNN F1 Score: {np.mean(knnScores)}\")"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Logistic Mean MSE: 0.16799999999999998\n",
            "KNN Mean MSE: 0.356\n",
            "---------\n",
            "Logistic F1 Score: 0.8537218191901557\n",
            "KNN F1 Score: 0.6849915391281238\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}