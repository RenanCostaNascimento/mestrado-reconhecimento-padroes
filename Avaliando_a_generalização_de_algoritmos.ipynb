{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Avaliando a generalização de algoritmos.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN/dvt7bGfNgq8cSK8b3oRG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RenanCostaNascimento/mestrado-reconhecimento-padroes/blob/main/Avaliando_a_generaliza%C3%A7%C3%A3o_de_algoritmos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mqw1_y01BNZ"
      },
      "source": [
        "O objetivo deste Notebook é utilizar duas formas de avaliação para comparar classificadores e verificar qual é a melhor forma. Cada forma se avaliação será executada 10 vezes, e a média dos resultados indicará os resultados. Os classificadores escolhidos são o [Logistic Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) e o [KNN](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) do scikit-learn. Já as formas de avaliação serão: usar um etapa de processamento (StandardScale) da base toda, e usar uma combinação de GridSearch, Pipeline e StandardScale. Vamos começar importando a base de dados [Heart Disease UCI do Kaggle](https://www.kaggle.com/ronitf/heart-disease-uci). É um dataset que indica se a pessoa tem alguma condição cardíaca com base nas suas informações médicas.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZA9LrvqOyoUG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "42456114-2abf-4644-bbbc-39bfd71fc40e"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "dataset = pd.read_csv('/content/heart.csv')\n",
        "dataset.head(3)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>63</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>145</td>\n",
              "      <td>233</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>150</td>\n",
              "      <td>0</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>37</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>130</td>\n",
              "      <td>250</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>187</td>\n",
              "      <td>0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>41</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>130</td>\n",
              "      <td>204</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>172</td>\n",
              "      <td>0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age  sex  cp  trestbps  chol  fbs  ...  exang  oldpeak  slope  ca  thal  target\n",
              "0   63    1   3       145   233    1  ...      0      2.3      0   0     1       1\n",
              "1   37    1   2       130   250    0  ...      0      3.5      0   0     2       1\n",
              "2   41    0   1       130   204    0  ...      0      1.4      2   0     2       1\n",
              "\n",
              "[3 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iARPNBt52qAF"
      },
      "source": [
        "Os dados da base de dados devem ser pré-processados. Para tanto, vamos começar separando os dados em uma matriz de features (dados de entrada) e um vetor coluna com as classes (última coluna – “target” – do arquivo csv)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiolejW022Xj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2501304-143a-4799-eb87-aef8c0aa8433"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# transforma o dataset do pandas em np array\n",
        "featureMatrix = dataset.to_numpy()\n",
        "\n",
        "# extrai a ultima coluna da matrix\n",
        "labels = featureMatrix[:,len(featureMatrix[0]) - 1]\n",
        "\n",
        "# remove a ultima coluna da featureMatrix\n",
        "featureMatrix = np.delete(featureMatrix, len(featureMatrix[0]) - 1, 1)\n",
        "\n",
        "np.shape(featureMatrix), np.shape(labels)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((303, 13), (303,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHCUyk_NDYmt"
      },
      "source": [
        "Vamos agora para a primeira forma de avaliação. Vamos começar usando uma etapa de pré-processamento ([Standard Scaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)) da base inteira. Em seguida precisamos dividir nossa base de dados em treino e teste. Para fazer isso vamos utilizar a função [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) do sklearn. Por fim, vamos de fato treinar nossos modelos. Para garantir que a comparação dos classificadores seja feita da melhor forma possível, vamos treinar o modelo de 10 formas diferentes, cada uma com um random_state único. Isso nos dará 20 modelos distintos, um para cada classificador. Para facilitar o trabalho, abaixo definimos uma função que separa a base de dados em teste e treino, além de treinar os modelos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6vrffEhDiHu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "981eb067-3810-4325-da9b-82db8667356a"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "scaler = StandardScaler()\n",
        "standardFeatures = scaler.fit_transform(featureMatrix)\n",
        "\n",
        "def trainTestSplit(randomState):\n",
        "  return train_test_split(standardFeatures, labels, test_size=0.33, random_state=randomState)\n",
        "\n",
        "def trainModels(featuresTrain, labelsTrain):\n",
        "  # eu precisei colocar o max_iter=1000 porque estava dando esse erro sem ele:\n",
        "  #  ConvergenceWarning: lbfgs failed to converge (status=1): STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
        "  logisticModel = LogisticRegression(max_iter=10000)\n",
        "  logisticModel.fit(featuresTrain, labelsTrain)\n",
        "\n",
        "  knnModel = KNeighborsClassifier()\n",
        "  knnModel.fit(featuresTrain, labelsTrain)\n",
        "\n",
        "  return logisticModel, knnModel\n",
        "\n",
        "def evaluateModel(model, featuresTest, labelsTest):\n",
        "  prediction = model.predict(featuresTest)\n",
        "  return f1_score(labelsTest, prediction)\n",
        "\n",
        "logisticScores1 = []\n",
        "knnScores1 = []\n",
        "\n",
        "for test in range(10):\n",
        "  featuresTrain, featuresTest, labelsTrain, labelsTest = trainTestSplit(test)\n",
        "  logisticModel, knnModel = trainModels(featuresTrain, labelsTrain)\n",
        "\n",
        "  logisticF1Score = evaluateModel(logisticModel, featuresTest, labelsTest)\n",
        "  logisticScores1.append(logisticF1Score)\n",
        "\n",
        "  knnF1Score = evaluateModel(knnModel, featuresTest, labelsTest)\n",
        "  knnScores1.append(knnF1Score)\n",
        "\n",
        "print(\"Evaluation 1\")\n",
        "print(f\"Logistic F1 Score: {np.mean(logisticScores1)}\")\n",
        "print(f\"KNN F1 Score: {np.mean(knnScores1)}\")"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation 1\n",
            "Logistic F1 Score: 0.8496124344774874\n",
            "KNN F1 Score: 0.8385658681341935\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5W7384SLDs7"
      },
      "source": [
        "Na segunda forma de avaliação também vamos usar o StandardScaler, mas dessa vez vamos passá-lo dentro de um Pipeline. Além disso, usaremos o [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) para encontrar os hiperparâmetros dos estimadores automaticamente. Por fim, usaremos o [cross_validate](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html) para treinar. Para treinar os modelos 10 vezes, vamos usar o [RepeatedKFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RepeatedKFold.html) para garantir que em toda rodada os dois estimadores sejam treinados com a mesma configuração do fold."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3sZDQpsjQna",
        "outputId": "3b98405c-c3c6-47ea-ddaa-afb21b46105a"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "\n",
        "logisticPipeline = Pipeline([\n",
        "  (\"standardization\", scaler),\n",
        "  (\"classifier\", LogisticRegression(max_iter=10000))\n",
        "])\n",
        "logisticParams = { \"classifier__penalty\": [\"l2\", \"none\"] }\n",
        "logisticModel = GridSearchCV(logisticPipeline, logisticParams, scoring=\"f1\")\n",
        "\n",
        "knnPipeline = Pipeline([\n",
        "  (\"standardization\", scaler),\n",
        "  (\"classifier\", KNeighborsClassifier())\n",
        "])\n",
        "knnParams = { \"classifier__n_neighbors\": [3, 5, 7] }\n",
        "knnModel = GridSearchCV(knnPipeline, knnParams, scoring=\"f1\")\n",
        "\n",
        "logisticScores2 = []\n",
        "knnScores2 = []\n",
        "\n",
        "for test in range(10):\n",
        "  repeatedKFold = RepeatedKFold(random_state=test)\n",
        "\n",
        "  logisticScore = cross_validate(logisticModel, featureMatrix, labels, scoring=\"f1\", cv=repeatedKFold)\n",
        "  logisticScores2.append(np.mean(logisticScore[\"test_score\"]))\n",
        "\n",
        "  knnScore = cross_validate(knnModel, featureMatrix, labels, scoring=\"f1\", cv=repeatedKFold)\n",
        "  knnScores2.append(np.mean(knnScore[\"test_score\"]))\n",
        "\n",
        "print(\"Evaluation 2\")\n",
        "print(f\"Logistic F1 Score: {np.mean(logisticScores2)}\")\n",
        "print(f\"KNN F1 Score: {np.mean(knnScores2)}\")"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation 2\n",
            "Logistic F1 Score: 0.8448686538806449\n",
            "KNN F1 Score: 0.838742082369803\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}